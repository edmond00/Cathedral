# Overview

Local LLM based textual RGP system inspired by Chain of thoughts technique and persona-like skill of disco elysium.
- classic game system implemented through c# class (avatar, skills, environment as **narration node** objects)
- But actions are generated by a local LLM
- goal is to keep coherence between LLM generated actions and game system
- LLM in charge in to find coherent actions
- Chain of Thoughts can help LLM to reach this goal
- But instead of hidding the COT, use it as a game feature
- the "thought" will be prompted differently depending on the avatar skills like some way to show what the avatar is thinking
- also include some placeholders for other features that will be added later
- PHASE 2 = the goal is to replace the current narration/system/UI of the "5. Launch Location Travel Mode (Phase 1)" mode of the app but concepts are reused



## Narration Node

- represent a short segment of narration context
- define some **context keywords** that are important in this context
- define possible outcomes when an action succeed in this context
    - contextual outcomes (depending on the current node)
        - possible switch to other narration node (=narration graph)
        - gameplay reward (new item, new skill)
        - encounters (fighting or conversations that will be added later)
    - humors change : always available
        - increase/decrease some avatar body humors
- each outcome is linked to 1 or multiples **context keywords** and can be obtained only when interacting with this keyword

## Avatar

Will at first be defined by :
- body parts that each have a level (equivalent to RPG character characteristic level but more fine grained)
    - **Lower Limbs** — locomotion, pursuit, evasion  
    - **Upper Limbs** — force, manipulation, combat  
    - **Thorax** — breath, voice, exertion  
    - **Viscera** — vitality, endurance, bodily resilience  
    - **Heart (Emotion)** — emotion, courage, social impulse  
    - **Fingers** — precision, craft, fine control  
    - **Feet** — balance, grounding, stealth  
    - **Backbone** — posture, stability, composure  
    - **Ears** — hearing, rhythm, vigilance  
    - **Eyes** — perception, reading, targeting  
    - **Tongue** — speech, persuasion, taste  
    - **Nose** — scent, tracking, discernment  
    - **Cerebrum (Reasoning)** — logic, planning, abstraction  
    - **Cerebellum (Motor Coordination)** — coordination, timing, bodily harmony  
    - **Anamnesis (Primary Memory)** — recall, learned knowledge, tradition  
    - **Hippocampus (Imagination)** — creativity, imagery, invention  
    - **Pineal Gland (Residual Memory)** — intuition, reflection, inner insight

- a subset of skills from a large skill bank
- 10 body humors that can see their "quantity" increase/decrease. Can just be empty placeholder for now but can increase/decrease of humors can be outcome for actions that don't find concrete consequences 
    1) Black Bile : Bodily heaviness, exhaustion, somatic weight
    2) Yellow Bile : Aggression, drive, irritation, action bias
    3) Appetitus : Craving, compulsion, fixation on consumption or relief
    4) Melancholia : Mental heaviness, fixation, brooding insight
    5) Ether : Dissolution of cohesion, altered perception, fading memory
    6) Phlegm : Inertia, calm, emotional dampening, resistance
    7) Blood : Warmth, vitality, confidence, social ease
    8) Voluptas : Pleasure, comfort, sensory reward
    9) Laetitia : Joy, morale, lightness of spirit
    10) Euphoria : Artificial elevation, overstimulation, manic uplift

## Skills

- where they can use in the RP-COT flow
- specific prompt they will use in the RP-COT flow = **skill prompting**
- level using during RNG check
- associated with 1 or several body part (association will be used later)
- a skill can have multiple function (both perception/thinking for example)
- other skill functions like fighting skill or conversation skill will be added later, for now only perception/thinking/action is ok
- here some examples of skills, but final goal is to have hundreds of them
    - brute force
    - open mind
    - finesse
    - chaos theory
    - algebraic analysis
    - consciousness
    - opportunism
    - sneak art
    - cunning art
    - logical reasoning
    - nihilism
    - theater
    - opera
    - uppercut
    - wrestle
    - athletism
    - thermodynamism
    - fluid mechanism
    - ballistic
    - dance
    - body language
    - buffoonery
    - investigation
    - sadism
    - masochism
    - charm
    - aesthetic
    - kick
    - bite
    - perfume science
    - equilibrium
    - childish play
    - mycology
    - ...

## Observations

- Entry of a narration
- based on **observation skills** (listening, visual analyze, ...)
- LLM generate small text describing one or several obervations observed by the avatar
- text is constrained through GBNF/prompting to include some of the Narration Node keyword
- The narration tone/style is defined by the skill by a **skill prompting**

## Context Keywords

- **Context keywords** of an observation narration text are highlighted like a link in website text
- Through a **LLM evaluation**,  each keywords is associatied with a **thinking skill** (strategy, intuition, focus, logic, ...)
- putting the mouse over this keyword will show the corresponding **thinking skill**
- clicking on this skill will trigger the **thinking* process

## Thinking

- find a list of actions that have coherent :
    - **context keyword** : the one player clicked on
    - **thinking skill** : skill that was associated to the keyword
    - **action skill** : one of the avatar **action skills** selected by the LLM
    - success outcome : randomly preselected from the narration node possible outcome

## Actions

- player can click on one of the actions generated byt the thinking process
- skill check based on the **action skill** level is rolled
- LLM narrated outcome
- success outcome was predefined during the **thinking** process
- Use LLM evaluation to evaluate most coherent faillure outcome
- if succcess outcome is new **narration node**, loop back

## UI

Will require :
- main UI is the display of multiples narrations blocks with scrolling system to scroll the current narration if it get too long (see src/terminal/terminalHUD.cs)
    - the narration UI is clear only after the outcome of the selected action
      - it should be possible to click on keyword, look at the proposed action, click on an other keywords to check other possible action, finaly select an action of the first keyword
      - some "action thinking limit" will be considered later to avoid unrolling too much without taking any action
      - use color to differentiate narration, skills name, clickable keywords, clickable actions, ...
- example of the main UI
        ```
        [PERCEPTION SKILL NAME 1]
        narration block ....
        .... <keyword> ....
        ....

        [PERCEPTION SKILL NAME 2]
        narration block ....
        .... <keyword> ....
        ....

        [THINKING SKILL NAME 1]
        narration block ....
        ....
        ....

        > [ACTION SKILL NAME] action description
        > [ACTION SKILL NAME] action description
        > [ACTION SKILL NAME] action description
        > [ACTION SKILL NAME] action description


        [THINKING SKILL NAME 2]
        narration block ....
        ....
        ....

        > [ACTION SKILL NAME] action description
        > [ACTION SKILL NAME] action description


        ```
- mouse centered terminal above the screen grid terminal : see src/terminal/PopupTerminalHUD.cs
    - show some information when the mouse is on a clickable text (keyword, action)
    - when click on a keyword, use it to display possible thinking skill to use on this keyword, the player then click on a thinking skill and the thinking narration 
- some kind of transition between to sequence (skill check result, fail/success result dispaly, ...). Then the main narration UI is clear and shown again if a new narration node has been activated

## LLM communication

it should be possible to reuse the code of `src/LLM`.
- always request JSON format output as some system info will often be requested in addition to the narration text
- Constrain the JSON format and JSON fields/content output with GBNF

### LLM evaluation functions

- asking several questions that can be answered by yes/no to the LMM
- only request 1 next token
- sum up probabilites of yes and no for each questions
- return a score based on the ratio of this sum


## Required content to create

- several narration node, linked together, representing the exploration of a forest
- various skills, skill not related to forest exploration also needed to verify how LLM handle this case
- various items, ok to focus on items that can be found in a forest (plants, ...), items gameplay will be added later but grouping/tagging system could be needed to efficiently link item to narration nodes
- avatar class, including placeholders for future features (inventory, humors) as having this placeholders can help checking the base flow
- UI (reusing already implemented char based terminal like UI/HUD/Popup)
- main flow : LLM communication /player interation, can be inspired by the current mode 5 of the app
- including this new flow in the mode 5

### Deprecated content to remove or ignore

- data/skills.csv and data/items are deprecated
- current location blueprint system (src/glyph/microworld/LocationBlueprint.cs, src/glyph/microworld/LocationGenerator.cs, ...) will be deprecated and replace by the more flexible Narration Node system
- current narration UI/narration system need to be replaced


# Demo Flow Example

The demo will focus on a forest exploration

- Some c# classes defines
  - a list of skills for the avatar define by
    - 1 or multiple functions between observation, thinking and actions
    - observations and thinking skills have an hardcoded unique prompt that will be used with the local LLM
  - The `NarrationNodes` of a forest
    - nodes defining several sublocations : a clearing, a stream, a grove, a pond, a giant tree, a path, a den...
    - each nodes have its own keywords : buisson, feuilles, plantes, ronces, oiseaux, tronc, mousse, champignon, fleur, ...
    - each nodes have its own success : several plant items, possibilities to learn nature/botany related skills, possibilities to get animal companion, ...
    - a flag say if it can be the entry node or not. Entry node is the first node to be active when entering a new location, it is sampled among all the possible entry node
- an entry node of the forest is sampled
- 1~3 perception skills are sampled
- perception narrations blocks are generated with the skill prompts

- keywords of this narration are highlighted and clickable
- when clicking on a keyword, open pop-up to select a thinking skill 
- when clicking a thinking skill, LLM is given this skill prompt + context (keyword, location, ...) + list of possible outcome + possible success outcome with the goal to find coherent actions and should produce
    - Some Chain-of-thought like reasoning explaining how available skills could be used to reach possible success outcome in the tone of the skill prompt
    - based on this COT, a list (skill,outcome,action), where skill and outcome can only be choose from a predefined list (GBNF constraint) and action freely written (but must start by "you try ...", GBNF constraint)
- the LLM generation actions are clickable, keywords are also still clickable
- if click on actions, switch to skill check transition :
    - first, ask some question to the LLM to see if the actions is possible,coherent,not out of context (similar to how `src/game/ActionScorer.cs` and `src/game/CriticEvaluator` currently work)
    - if the LLM evaluated action score is below a certain threshold, action automatic fail
    - else, a RNG skill check based on the action skill level is done to decide if the action succeed or not
    - if failure, LLM evaluate possible malus of the action (again similar to how `src/game/ActionScorer.cs` and `src/game/CriticEvaluator` currently work)
    - if success, the outcome previously decided by the thinking skill is realized
    - if success outcome is a new narration node, clear narrations menu and loop back to the beginning of narration flow
    - else, return to travel mode



# Prompt Example

(TODO : refactor this example to take into account LLM answers always need to be JSON format, example below is just to give a reference of the expected tone of the narration texts)

## Prompt

You are the personality and inner voice of the skill **Algebraic Analysis**.

Algebraic Analysis is a cold, abstract, pattern-obsessed way of thinking.
It perceives the world as variables, constraints, systems, transformations,
inputs and outputs. It does not care about emotions, beauty, or intent.
It constantly tries to reduce situations to symbolic relations, mappings,
optimizations, equivalences, and edge cases.

When speaking, Algebraic Analysis sounds analytical, detached, slightly pedantic.
It explains how unrelated actions might still fit the same underlying structure.
It enjoys forcing coherence where none is obvious.

---

Context (neutral description):
The character is standing in a forest, observing a tree.
Available action skills are: swimming, shouting, running, pickpocket, trampling.

---

Task:
You must generate actions by combining:
- the perception (tree in a forest)
- the thinking skill personality (Algebraic Analysis)
- each available action skill

Output format (STRICT):

1. First, write ONE short paragraph of inner thinking,
written in the voice of Algebraic Analysis,
explaining how these action skills could be abstractly
related to the current situation.

2. Then, write EXACTLY one concrete action for EACH action skill,
in the following format:

- Swimming: <one short concrete action>
- Shouting: <one short concrete action>
- Running: <one short concrete action>
- Pickpocket: <one short concrete action>
- Trampling: <one short concrete action>

Rules:
- Do not add extra commentary.
- Do not explain the rules.
- Do not mention the player or the game.
- The thinking paragraph must sound like an internal analytical monologue.
- Actions must logically follow from the thinking, even if unusual.

# Answer

In the forest, the tree stands as a variable within a system of constraints and transformations, its branches and leaves representing inputs and outputs in a natural network. Swimming, shouting, running, pickpocketing, and trampling can be abstractly mapped onto this structure, each action a potential transformation or optimization within the environment. Swimming might symbolize a fluid adaptation to the forest's constraints, while shouting could represent a signal transformation, echoing through the system. Running might be seen as a traversal through the forest's variables, optimizing movement efficiency. Pickpocketing could be interpreted as extracting specific inputs from the system, and trampling as a forceful transformation, altering the forest's structure. Each action, though seemingly disparate, fits into the overarching framework of symbolic relations and transformations.

Swimming: Analyze the tree's branches as fluid pathways, optimizing movement through the forest's constraints.
Shouting: Emit a signal transformation, echoing through the forest's variables to test their response.
Running: Traverse the forest's system, optimizing movement efficiency through its variables.
Pickpocket: Extract specific inputs from the tree's system, analyzing its structural components.
Trampling: Apply a forceful transformation to the forest's variables, altering its structure.